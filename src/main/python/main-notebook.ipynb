{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45909d062047387d",
   "metadata": {},
   "source": [
    "# Obiettivo del progetto\n",
    "Dopo aver analizzato e compreso i dati, si vuole studiare meglio la correlazione riscontrata tra distanza e prezzo e si è individuato l'obiettivo del progetto. L'obiettivo è quello di verificare se c’è una stagionalità, nella quale i prezzi per alcuni mesi sono molto più elevati rispetto ad altri o se ci sono grandi variazioni di prezzo tra i diversi mesi rispetto alle diverse distanze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5699d07ef8e27",
   "metadata": {},
   "source": [
    "## Descrizione del job proposto\n",
    "Avendo a disposizione un solo file *.csv* si è pensato si usare un pattern di tipo *self-join*:\n",
    "\n",
    "-\t**Prima aggregazione**: aggregare per ogni combinazione di aeroporto di partenza e destinazione (*startingAeroport* e *destinationAeroport*) per ottenere la distanza media di viaggio (*totalTravelDistance*). A partire dalla distanza media generare una nuova colonna che indichi la fascia di distanza del volo (breve distanza, media distanza, lunga distanza);\n",
    "\n",
    "-\t**Join**: unire il dataset originale con il risultato ottenuto;\n",
    "\n",
    "-\t**Seconda aggregazione**: aggregare per fascia di distanza e mese (*flightDate*, da cui si ricava il mese) per ottenere per ciascuna combinazione il prezzo medio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae506c8e35674206",
   "metadata": {},
   "source": [
    "### Caricamento libreria Spark\n",
    "\n",
    "Per prima cosa, si deve importare la libreria spark per avviare una `spark-shell`; in seguito verrà mostrato il link tramite il quale è possibile accedere all'interfaccia utente di Spark."
   ]
  },
  {
   "cell_type": "code",
   "id": "fb23d8dd5e72ce9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:32:41.952125Z",
     "start_time": "2025-01-23T21:32:28.690276Z"
    }
   },
   "source": [
    "import org.apache.spark"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.9:4040\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1737667953668)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f69bc549d0a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "// DO NOT EXECUTE - this is needed just to avoid showing errors in the following cells\n",
    "val sc = spark.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c45630c708235f",
   "metadata": {},
   "source": [
    "### Parser del file .csv\n",
    "\n",
    "Nella cella sottostante è implementata una `case class Flight` con come parametri tutte le colonne(*) presenti nel file .csv descritto nel notebook [data-exploration.ipynb](./data-exploration.ipynb) e un `FlightParser` che consentente l'estrazione delle informazioni necessarie per popolare l'oggetto RDD di Spark.\n",
    "\n",
    "(*) per risolvere il `job` proposto verranno utilizzate solo alcune delle colonne."
   ]
  },
  {
   "cell_type": "code",
   "id": "51c8479048aa4b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:32:54.418047Z",
     "start_time": "2025-01-23T21:32:52.493144Z"
    }
   },
   "source": [
    "import java.text.SimpleDateFormat\n",
    "import java.util.Calendar\n",
    "\n",
    "/**\n",
    " * Flight case class.\n",
    " */\n",
    "case class Flight(\n",
    "    legId: String,\n",
    "    searchMonth: Int,\n",
    "    flightMonth: Int,\n",
    "    startingAirport: String,\n",
    "    destinationAirport: String,\n",
    "    fareBasisCode: String,\n",
    "    travelDuration: String,\n",
    "    elapsedDays: Int,\n",
    "    isBasicEconomy: Boolean,\n",
    "    isRefundable: Boolean,\n",
    "    isNonStop: Boolean,\n",
    "    baseFare: Double,\n",
    "    totalFare: Double,\n",
    "    seatsRemaining: Int,\n",
    "    totalTravelDistance: Double,\n",
    "    segmentsDepartureTimeEpochSeconds: String,\n",
    "    segmentsDepartureTimeRaw: String,\n",
    "    segmentsArrivalTimeEpochSeconds: String,\n",
    "    segmentsArrivalTimeRaw: String,\n",
    "    segmentsArrivalAirportCode: String,\n",
    "    segmentsDepartureAirportCode: String,\n",
    "    segmentsAirlineName: String,\n",
    "    segmentsAirlineCode: String,\n",
    "    segmentsEquipmentDescription: String,\n",
    "    segmentsDurationInSeconds: String,\n",
    "    segmentsDistance: String,\n",
    "    segmentsCabinCode: String\n",
    ") extends Serializable\n",
    "\n",
    "/**\n",
    " * Flight parser.\n",
    " */\n",
    "object FlightParser extends Serializable {\n",
    "\n",
    "  val comma = \",\"\n",
    "\n",
    "  /**\n",
    "   * Convert from date (String) to month (Int).\n",
    "   * @param dateString the date\n",
    "   * @return the month\n",
    "   */\n",
    "  def monthFromDate(dateString: String): Int = {\n",
    "    val sdf = new SimpleDateFormat(\"yyyy-MM-dd\")\n",
    "    val date = sdf.parse(dateString.trim)\n",
    "    val cal = Calendar.getInstance()\n",
    "    cal.setTime(date)\n",
    "    cal.get(Calendar.MONTH) + 1\n",
    "  }\n",
    "\n",
    "  /**\n",
    "   * Function to parse flights records.\n",
    "   * @param line that has to be parsed\n",
    "   * @return Flight object, None in case of input errors\n",
    "   */\n",
    "  def parseFlightLine(line: String): Option[Flight] = {\n",
    "    try {\n",
    "      val columns = line.split(comma)\n",
    "      Some(\n",
    "        Flight(\n",
    "          legId = columns(0).trim,\n",
    "          searchMonth = monthFromDate(columns(1)),\n",
    "          flightMonth = monthFromDate(columns(2)),\n",
    "          startingAirport = columns(3).trim,\n",
    "          destinationAirport = columns(4).trim,\n",
    "          fareBasisCode = columns(5).trim,\n",
    "          travelDuration = columns(6).trim,\n",
    "          elapsedDays = columns(7).trim.toInt,\n",
    "          isBasicEconomy = columns(8).trim.toBoolean,\n",
    "          isRefundable = columns(9).trim.toBoolean,\n",
    "          isNonStop = columns(10).trim.toBoolean,\n",
    "          baseFare = columns(11).trim.toDouble,\n",
    "          totalFare = columns(12).trim.toDouble,\n",
    "          seatsRemaining = columns(13).trim.toInt,\n",
    "          totalTravelDistance = columns(14).trim.toDouble,\n",
    "          segmentsDepartureTimeEpochSeconds = columns(15).trim,\n",
    "          segmentsDepartureTimeRaw = columns(16).trim,\n",
    "          segmentsArrivalTimeEpochSeconds = columns(17).trim,\n",
    "          segmentsArrivalTimeRaw = columns(18).trim,\n",
    "          segmentsArrivalAirportCode = columns(19).trim,\n",
    "          segmentsDepartureAirportCode = columns(20).trim,\n",
    "          segmentsAirlineName = columns(21).trim,\n",
    "          segmentsAirlineCode = columns(22).trim,\n",
    "          segmentsEquipmentDescription = columns(23).trim,\n",
    "          segmentsDurationInSeconds = columns(24).trim,\n",
    "          segmentsDistance = columns(25).trim,\n",
    "          segmentsCabinCode = columns(26).trim\n",
    "        )\n",
    "      )\n",
    "    } catch {\n",
    "      case e: Exception =>\n",
    "        // println(s\"Errore durante il parsing della riga '$line': ${e.getMessage}\")\n",
    "        None\n",
    "    }\n",
    "  }\n",
    "}"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import java.text.SimpleDateFormat\r\n",
       "import java.util.Calendar\r\n",
       "defined class Flight\r\n",
       "defined object FlightParser\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "d195400e1cea1b18",
   "metadata": {},
   "source": [
    "### Caricamento dei dati\n",
    "\n",
    "Con la seguente cella si effettua il caricamento del file *itineraries-sample\\<N\\>.csv*, dove con N si intende la percentuale di dati campionati dal file originale di 31,09 GB.\n",
    "\n",
    "I file disponibili sono scaricabili dalla cartella su [OneDrive](https://liveunibo-my.sharepoint.com/:f:/g/personal/giulia_nardicchia_studio_unibo_it/Ei2686kRO3JFrY-4LnImGpwBtge9FRErDnIgvT2h2QB-Pg?e=VrufWl) e hanno percentuale: `02`, `16` e `33`."
   ]
  },
  {
   "cell_type": "code",
   "id": "8681b935c9353693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:32:58.576349Z",
     "start_time": "2025-01-23T21:32:57.002409Z"
    }
   },
   "source": [
    "val datasetsPath = \"../../../datasets/big/\"\n",
    "val fileName = \"itineraries-sample02.csv\"\n",
    "\n",
    "val rawData = sc.textFile(datasetsPath + fileName)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasetsPath: String = ../../../datasets/big/\r\n",
       "fileName: String = itineraries-sample02.csv\r\n",
       "rawData: org.apache.spark.rdd.RDD[String] = ../../../datasets/big/itineraries-sample02.csv MapPartitionsRDD[1] at textFile at <console>:30\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "55ad3c19d0de51fa",
   "metadata": {},
   "source": [
    "Trasformazione di un RDD composto da dati grezzi (*rawData*) in un RDD di oggetti `Flight`. La funzione `FlightParser.parseFlightLine` analizza ogni riga. `flatMap` appiattisce i risultati, scartando automaticamente le righe non valide."
   ]
  },
  {
   "cell_type": "code",
   "id": "ba8c35cd3020a7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:33:02.345990Z",
     "start_time": "2025-01-23T21:33:00.841046Z"
    }
   },
   "source": [
    "val rddFlights = rawData.flatMap(FlightParser.parseFlightLine)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddFlights: org.apache.spark.rdd.RDD[Flight] = MapPartitionsRDD[2] at flatMap at <console>:28\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "adcd44f9230e1434",
   "metadata": {},
   "source": [
    "Per verificare che non ci siano stati problemi di *parsing*, con la cella seguente si vuole eseguire un'azione. La funzione `count()` calcola il numero di righe valide."
   ]
  },
  {
   "cell_type": "code",
   "id": "411a20cf90856722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:33:11.882421Z",
     "start_time": "2025-01-23T21:33:04.336324Z"
    }
   },
   "source": [
    "rddFlights.count()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Long = 1520662\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "1500dc766c51eab",
   "metadata": {},
   "source": [
    "### Prima aggregazione\n",
    "\n",
    "Innanzitutto si utilizza `map` per eliminare tutte le colonne che non servono a svolgere il job proposto e per trasformare i dati di tipo (chiave, valore). Si vuole aggregare per ogni combinazione di aeroporto di partenza e destinazione (*startingAeroport* e *destinationAeroport*) per ottenere la distanza media di viaggio (*totalTravelDistance*)."
   ]
  },
  {
   "cell_type": "code",
   "id": "fb3928b8618a571d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:33:16.003134Z",
     "start_time": "2025-01-23T21:33:14.346980Z"
    }
   },
   "source": [
    "val avgDistances = rddFlights\n",
    "  .map(flight => ((flight.startingAirport, flight.destinationAirport), flight.totalTravelDistance))\n",
    "  .aggregateByKey((0.0, 0))(\n",
    "    (acc, travelDistance) => (acc._1 + travelDistance, acc._2 + 1),\n",
    "    (acc1, acc2) => (acc1._1 + acc2._1, acc1._2 + acc2._2)\n",
    "  )\n",
    "  .mapValues { case (sumDistance, count) => sumDistance / count }"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avgDistances: org.apache.spark.rdd.RDD[((String, String), Double)] = MapPartitionsRDD[5] at mapValues at <console>:33\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "22f52f39-34a4-4c7c-832f-f40b96ce0570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:33:29.122944Z",
     "start_time": "2025-01-23T21:33:18.190354Z"
    }
   },
   "source": [
    "avgDistances.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[((String, String), Double)] = Array(((BOS,LGA),406.6977958842578), ((IAD,ORD),841.525204359673), ((EWR,PHL),1039.5994575045208), ((DTW,LGA),694.1526669795088), ((OAK,DFW),2123.889001864091), ((ATL,DEN),1513.575124745888), ((IAD,CLT),587.9657102869139), ((DEN,LGA),1804.57909562639), ((DTW,EWR),736.2682451253482), ((LGA,DFW),1455.155069582505), ((OAK,JFK),3126.575707702436), ((DEN,DTW),1578.6580700623254), ((JFK,IAD),703.4175354183374), ((ORD,MIA),1521.1334047682828), ((IAD,DFW),1363.3681891954557), ((DEN,PHL),1852.40172900494), ((OAK,DEN),1419.471807628524), ((BOS,JFK),261.94046744083494), ((SFO,JFK),2652.746982695943), ((DTW,MIA),1462.8436163714111), ((PHL,OAK),2949.3589503280223), ((CLT,LGA),665.3443708609271), ((DTW,JFK),842.9147381242387), ((ATL,IAD),647.0074156470153), (...\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "82f64718cfaaeafc",
   "metadata": {},
   "source": [
    "A partire dalla distanza media si vuole generare una nuova colonna che indichi la fascia di distanza del volo (breve distanza, media distanza, lunga distanza).\n",
    "\n",
    "Poiché usare valori numerici *hard coded* è una *bad practice*, si è deciso di utilizzare il minimo, il massimo e il numero di classi per calcolare dinamicamente l'intervallo delle fasce di distanza."
   ]
  },
  {
   "cell_type": "code",
   "id": "7b489572-22b4-4038-a7fa-0081398ed80d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:33:33.040859Z",
     "start_time": "2025-01-23T21:33:31.737221Z"
    }
   },
   "source": [
    "val (minDistance, maxDistance) = avgDistances\n",
    "    .aggregate((Double.MaxValue, Double.MinValue))(\n",
    "        (acc, value) => (math.min(acc._1, value._2), math.max(acc._2, value._2)),\n",
    "        (acc1, acc2) => (math.min(acc1._1, acc2._1), math.max(acc1._2, acc2._2))\n",
    "    )"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minDistance: Double = 185.0\r\n",
       "maxDistance: Double = 3366.947416137806\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "d113be73d8f55809",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:33:36.280100Z",
     "start_time": "2025-01-23T21:33:35.939633Z"
    }
   },
   "source": [
    "val numClasses = 3\n",
    "val range = (maxDistance - minDistance) / numClasses"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numClasses: Int = 3\r\n",
       "range: Double = 1060.649138712602\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "998c5f70d0a66232",
   "metadata": {},
   "source": [
    "Per calcolare l'intervallo in maniera equidistante sono stati adottati i seguenti limiti:\n",
    "- **Breve**: se la distanza media è inferiore a *minimo + intervallo*;\n",
    "\n",
    "- **Media**: se la distanza media è compresa tra *[minimo + intervallo; minimo + 2 * intervallo)*;\n",
    "\n",
    "- **Lunga**: se la distanza media è superiore a *minimo + (numero classi - 1) * intervallo*."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:33:48.365329Z",
     "start_time": "2025-01-23T21:33:47.728398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val classifiedDistances = avgDistances.mapValues {\n",
    "  case (avgDistance) => \n",
    "     val classification = if (avgDistance < minDistance + range) \"short\"\n",
    "     else if (avgDistance <= minDistance + (numClasses - 1) * range ) \"medium\"\n",
    "     else \"long\"\n",
    "    classification\n",
    "}"
   ],
   "id": "d48c6d16984e76a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifiedDistances: org.apache.spark.rdd.RDD[((String, String), String)] = MapPartitionsRDD[6] at mapValues at <console>:30\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "8f60e39b-ecff-4bcf-ab28-074ba9e0d677",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:33:52.398210Z",
     "start_time": "2025-01-23T21:33:51.283455Z"
    }
   },
   "source": "classifiedDistances.collect()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Array[((String, String), String)] = Array(((BOS,LGA),short), ((IAD,ORD),short), ((EWR,PHL),short), ((DTW,LGA),short), ((OAK,DFW),medium), ((ATL,DEN),medium), ((IAD,CLT),short), ((DEN,LGA),medium), ((DTW,EWR),short), ((LGA,DFW),medium), ((OAK,JFK),long), ((DEN,DTW),medium), ((JFK,IAD),short), ((ORD,MIA),medium), ((IAD,DFW),medium), ((DEN,PHL),medium), ((OAK,DEN),medium), ((BOS,JFK),short), ((SFO,JFK),long), ((DTW,MIA),medium), ((PHL,OAK),long), ((CLT,LGA),short), ((DTW,JFK),short), ((ATL,IAD),short), ((ATL,MIA),short), ((DTW,IAD),short), ((OAK,LGA),long), ((SFO,EWR),long), ((IAD,SFO),long), ((CLT,SFO),long), ((BOS,ATL),short), ((LAX,DEN),short), ((DEN,JFK),medium), ((BOS,LAX),long), ((SFO,IAD),long), ((DTW,DEN),medium), ((ORD,LGA),short), ((ATL,OAK),long), ((MIA,CLT),short), ((EWR,...\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "c24023d49bd4355e",
   "metadata": {},
   "source": [
    "### Join + Seconda aggregazione\n",
    "\n",
    "Si unisce il dataset originale con il risultato ottenuto, aggregando poi per fascia di distanza e mese (*flightDate*, da cui si ricava il mese) si ottiene per ciascuna combinazione il prezzo medio."
   ]
  },
  {
   "cell_type": "code",
   "id": "bc88d7785805c488",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:34:01.758152Z",
     "start_time": "2025-01-23T21:34:00.264854Z"
    }
   },
   "source": [
    "val resultJob = rddFlights\n",
    "  .map(flight => ((flight.startingAirport, flight.destinationAirport), (flight.flightMonth, flight.totalFare)))\n",
    "  .join(classifiedDistances)\n",
    "  .map {\n",
    "    case (_, ((flightMonth, totalFare), classification)) => ((flightMonth, classification), (totalFare, 1))\n",
    "  }\n",
    "  .reduceByKey((acc, totalFare) => (acc._1 + totalFare._1, acc._2 + totalFare._2))\n",
    "  .map {\n",
    "    case ((flightMonth, classification), (sumTotalFare, count)) => (flightMonth, classification, sumTotalFare / count)\n",
    "  }"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resultJob: org.apache.spark.rdd.RDD[(Int, String, Double)] = MapPartitionsRDD[13] at map at <console>:35\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "9cfcbba0-59f0-42fa-a35f-93b1b178ebc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:34:12.857810Z",
     "start_time": "2025-01-23T21:34:03.682420Z"
    }
   },
   "source": [
    "resultJob.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Array[(Int, String, Double)] = Array((9,long,405.4846256093827), (11,short,222.00556413449337), (11,long,382.2554902106178), (5,long,533.1691284153799), (7,short,290.6924974546775), (9,short,256.1263844227748), (4,long,480.8690961538476), (9,medium,293.22341323056406), (11,medium,254.47777319902355), (8,medium,322.54506223357464), (7,long,554.1280932802313), (6,long,598.8304861754743), (8,short,265.2235958197947), (5,medium,354.6517011517386), (10,short,259.31215532219113), (7,medium,382.5014410856043), (10,long,411.65239396939035), (5,short,278.2944923340169), (8,long,462.04696232908327), (6,short,296.05174334065094), (4,short,306.4335681610265), (6,medium,395.04683677556426), (10,medium,294.67349021285935), (4,medium,331.0029844885145))\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "78bfd7ca0e66fbb2",
   "metadata": {},
   "source": [
    "## Job Not Optimized\n",
    "\n",
    "A partire dal codice scritto nelle precedenti celle, si è proceduto a *\"rifattorizzare\"* l'implementazione, di seguito il *job* non ottimizzato."
   ]
  },
  {
   "cell_type": "code",
   "id": "004a6651-59d3-4191-8d5b-a9e60c15ed6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-23T21:34:49.777665Z",
     "start_time": "2025-01-23T21:34:42.971194Z"
    }
   },
   "source": [
    "val numClassesNO = 3\n",
    "\n",
    "val rddFlightsNO = rawData.flatMap(FlightParser.parseFlightLine)\n",
    "    // (k,v) => (startingAirport, destinationAirport), (totalTravelDistance, flightDate, totalFare))\n",
    "    .map(flight => ((flight.startingAirport, flight.destinationAirport),\n",
    "                    (flight.totalTravelDistance, flight.flightMonth, flight.totalFare)))\n",
    "\n",
    "val avgDistancesNO = rddFlightsNO\n",
    "    .aggregateByKey((0.0, 0))(\n",
    "        (acc, travelDistance) => (acc._1 + travelDistance._1, acc._2 + 1),\n",
    "        (acc1, acc2) => (acc1._1 + acc2._1, acc1._2 + acc2._2)\n",
    "    )\n",
    "    // (k,v) => ((startingAirport, destinationAirport), avgDistance)\n",
    "    .mapValues { case (sumDistance, count) => sumDistance / count }\n",
    "\n",
    "val (minDistanceNO, maxDistanceNO) = avgDistancesNO\n",
    "    .aggregate((Double.MaxValue, Double.MinValue))(\n",
    "        (acc, avgDistance) => (math.min(acc._1, avgDistance._2), math.max(acc._2, avgDistance._2)),\n",
    "        (acc1, acc2) => (math.min(acc1._1, acc2._1), math.max(acc1._2, acc2._2))\n",
    "    )\n",
    "\n",
    "val rangeNO = (maxDistanceNO - minDistanceNO) / numClassesNO\n",
    "\n",
    "val resultJobNotOptimized = avgDistancesNO\n",
    "    .mapValues {\n",
    "      case d if d < minDistanceNO + rangeNO => \"short\"\n",
    "      case d if d < minDistanceNO + (numClassesNO - 1) * rangeNO => \"medium\"\n",
    "      case _ => \"long\"\n",
    "    } // (k,v) => ((startingAirport, destinationAirport), classification)\n",
    "    .join(rddFlightsNO)\n",
    "    .map { case (_, (classification, (_, month, totalFare))) => ((month, classification), (totalFare, 1)) }\n",
    "    .reduceByKey((acc, totalFare) => (acc._1 + totalFare._1, acc._2 + totalFare._2))\n",
    "    .map { case ((month, classification), (sumTotalFare : Double, count: Int)) => (month, classification, sumTotalFare / count) }"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numClassesNO: Int = 3\r\n",
       "rddFlightsNO: org.apache.spark.rdd.RDD[((String, String), (Double, Int, Double))] = MapPartitionsRDD[15] at map at <console>:32\r\n",
       "avgDistancesNO: org.apache.spark.rdd.RDD[((String, String), Double)] = MapPartitionsRDD[17] at mapValues at <console>:41\r\n",
       "minDistanceNO: Double = 185.0\r\n",
       "maxDistanceNO: Double = 3366.947416137806\r\n",
       "rangeNO: Double = 1060.649138712602\r\n",
       "resultJobNotOptimized: org.apache.spark.rdd.RDD[(Int, String, Double)] = MapPartitionsRDD[24] at map at <console>:60\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "0efbfcf7-5bb8-48f6-9a99-573b9edbb153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:35:02.051415Z",
     "start_time": "2025-01-23T21:34:53.021464Z"
    }
   },
   "source": [
    "resultJobNotOptimized.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Array[(Int, String, Double)] = Array((9,long,405.4846256093826), (11,short,222.00556413449337), (11,long,382.2554902106179), (5,long,533.1691284153799), (7,short,290.69249745467766), (9,short,256.1263844227749), (4,long,480.8690961538476), (9,medium,293.22341323056395), (11,medium,254.4777731990232), (8,medium,322.545062233574), (7,long,554.1280932802313), (6,long,598.8304861754746), (8,short,265.223595819795), (5,medium,354.65170115173936), (10,short,259.3121553221906), (7,medium,382.50144108560403), (10,long,411.65239396939035), (5,short,278.294492334017), (8,long,462.04696232908344), (6,short,296.05174334065117), (4,short,306.4335681610265), (6,medium,395.0468367755642), (10,medium,294.67349021286043), (4,medium,331.0029844885145))\r\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "a0f46674-634a-458a-ab23-e48cdda23546",
   "metadata": {},
   "source": [
    "### Considerazioni sulle ottimizzazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bcf39a-68ec-42e2-a12c-798c49de3829",
   "metadata": {},
   "source": [
    "- Cache/Persist\n",
    "- Repartition/PartitionBy\n",
    "- Broadcast variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3bc2fbd8d752bfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:44:54.591520Z",
     "start_time": "2025-01-23T10:44:53.824429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Option[org.apache.spark.Partitioner] = None\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddFlightsNO.partitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bd9a2e0726109e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:44:54.976896Z",
     "start_time": "2025-01-23T10:44:54.594363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Int = 19\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddFlightsNO.partitions.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bebe4e41d4c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddFlightsNO.mapPartitionsWithIndex((index, iter) => Iterator((index, iter.size))).collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc37760176ffe090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:56:29.369262Z",
     "start_time": "2025-01-23T10:56:28.437017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res13: Int = 8\r\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java.lang.Runtime.getRuntime.availableProcessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b99a90a1972245d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:03:18.876072Z",
     "start_time": "2025-01-23T11:03:18.565568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res22: Int = 8\r\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b5fde3d3054573f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:15:34.081673Z",
     "start_time": "2025-01-23T11:15:33.924557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.eventLog.enabled: true\r\n",
      "spark.driver.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\r\n",
      "spark.driver.cores: 4\r\n",
      "spark.app.submitTime: 1737629015318\r\n",
      "spark.eventLog.dir: file:///c:/spark-3.5.1-bin-hadoop3/history/\r\n",
      "spark.driver.memory: 4g\r\n",
      "spark.app.startTime: 1737629015468\r\n",
      "spark.executor.id: driver\r\n",
      "spark.app.name: spylon-kernel\r\n",
      "spark.repl.class.uri: spark://192.168.1.9:57307/classes\r\n",
      "spark.history.fs.logDirectory: file:///c:/spark-3.5.1-bin-hadoop3/history/\r\n",
      "spark.repl.class.outputDir: C:\\Users\\HP\\AppData\\Local\\Temp\\tmpx15xnw93\r\n",
      "spark.driver.port: 57307\r\n",
      "spark.rdd.compress: True\r\n",
      "spark.executor.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\r\n",
      "spark.serializer.objectStreamReset: 100\r\n",
      "spark.master: local[*]\r\n",
      "spark.submit.pyFiles: \r\n",
      "spark.submit.deployMode: client\r\n",
      "spark.app.id: local-1737629016653\r\n",
      "spark.driver.host: 192.168.1.9\r\n",
      "spark.ui.showConsoleProgress: true\r\n"
     ]
    }
   ],
   "source": [
    "sc.getConf.getAll.foreach { case (key, value) =>\n",
    "  println(s\"$key: $value\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64baa8da4978b354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:15:19.638414Z",
     "start_time": "2025-01-23T11:15:19.535545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: String = 4\r\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf.get(\"spark.driver.cores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fb60a-caca-4e64-b447-6c0f1a49cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.getConf.get(\"spark.driver.memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2914a2-411f-459c-b825-513953211cb3",
   "metadata": {},
   "source": [
    "## Job Optimized\n",
    "\n",
    "Una volta capite quali tecniche di ottimizzazione sono da adottare per migliorare le performance, sia in termini di tempo sia in termini di computazione, è stato riscritto il *main job* e si è ottenuto il seguente codice."
   ]
  },
  {
   "cell_type": "code",
   "id": "9213ee75-718d-49ef-99d8-e84dc43cbd67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:35:58.280494Z",
     "start_time": "2025-01-23T21:35:48.521937Z"
    }
   },
   "source": [
    "import org.apache.spark.storage.StorageLevel._\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "val numClassesO = 3\n",
    "val numPartitions = 24\n",
    "val p = new HashPartitioner(numPartitions)\n",
    "\n",
    "val rddFlightsO = rawData.flatMap(FlightParser.parseFlightLine)\n",
    "    // (k,v) => (startingAirport, destinationAirport), (totalTravelDistance, flightDate, totalFare))\n",
    "    .map(flight => ((flight.startingAirport, flight.destinationAirport), \n",
    "                    (flight.totalTravelDistance, flight.flightMonth, flight.totalFare)))\n",
    "    .partitionBy(p)\n",
    "    //.persist(MEMORY_AND_DISK_SER)\n",
    "    .cache()\n",
    "\n",
    "val avgDistancesO = rddFlightsO\n",
    "    .aggregateByKey((0.0, 0))(\n",
    "    (acc, travelDistance) => (acc._1 + travelDistance._1, acc._2 + 1),\n",
    "    (acc1, acc2) => (acc1._1 + acc2._1, acc1._2 + acc2._2)\n",
    "    )\n",
    "    // (k,v) => ((startingAirport, destinationAirport), avgDistance)\n",
    "    .mapValues { case (sumDistance, count) => sumDistance / count }\n",
    "    //.persist(MEMORY_AND_DISK_SER)\n",
    "    .cache()\n",
    "\n",
    "val (minDistanceO, maxDistanceO) = sc.broadcast(avgDistancesO\n",
    "    .aggregate((Double.MaxValue, Double.MinValue))(\n",
    "        (acc, avgDistance) => (Math.min(acc._1, avgDistance._2), Math.max(acc._2, avgDistance._2)),\n",
    "        (acc1, acc2) => (Math.min(acc1._1, acc2._1), Math.max(acc1._2, acc2._2))\n",
    "    )\n",
    ").value\n",
    "\n",
    "val rangeO = (maxDistanceO - minDistanceO) / numClassesO\n",
    "\n",
    "val resultJobOptimized = avgDistancesO\n",
    "    .mapValues {\n",
    "      case d if d < minDistanceNO + rangeNO => \"short\"\n",
    "      case d if d < minDistanceNO + (numClassesNO - 1) * rangeNO => \"medium\"\n",
    "      case _ => \"long\"\n",
    "    } // (k,v) => ((startingAirport, destinationAirport), classification)\n",
    "    .join(rddFlightsO)\n",
    "    .map { case (_, (classification, (_, month, totalFare))) => ((month, classification), (totalFare, 1)) }\n",
    "    .reduceByKey((acc, totalFare) => (acc._1 + totalFare._1, acc._2 + totalFare._2))\n",
    "    .map { case ((month, classification), (sumTotalFare, count)) => (month, classification, sumTotalFare / count) }"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.storage.StorageLevel._\r\n",
       "import org.apache.spark.HashPartitioner\r\n",
       "numClassesO: Int = 3\r\n",
       "numPartitions: Int = 24\r\n",
       "p: org.apache.spark.HashPartitioner = org.apache.spark.HashPartitioner@18\r\n",
       "rddFlightsO: org.apache.spark.rdd.RDD[((String, String), (Double, Int, Double))] = ShuffledRDD[27] at partitionBy at <console>:43\r\n",
       "avgDistancesO: org.apache.spark.rdd.RDD[((String, String), Double)] = MapPartitionsRDD[29] at mapValues at <console>:53\r\n",
       "minDistanceO: Double = 185.0\r\n",
       "maxDistanceO: Double = 3366.947416137806\r\n",
       "rangeO: Double = 1060.649138712602\r\n",
       "resultJobOptimized: org.apache.spark.rdd.RDD[(Int, String, Double)] = MapPartitionsRDD[36] at map at <console>:75\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e60328d17e7ae1e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:46:13.819719Z",
     "start_time": "2025-01-23T10:46:13.264071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Int = 24\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddFlightsO.partitions.length"
   ]
  },
  {
   "cell_type": "code",
   "id": "f50cb4e7-dabe-4415-a9b8-77f778977fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:36:02.963706Z",
     "start_time": "2025-01-23T21:36:01.047646Z"
    }
   },
   "source": [
    "resultJobOptimized.collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Array[(Int, String, Double)] = Array((4,medium,331.0029844885144), (6,short,296.05174334064077), (8,short,265.2235958197836), (11,medium,254.47777319902426), (6,medium,395.04683677555823), (9,short,256.12638442276415), (5,long,533.1691284153735), (8,medium,322.5450622335694), (11,long,382.2554902106189), (4,short,306.43356816102596), (10,short,259.31215532217783), (8,long,462.04696232908634), (10,long,411.65239396938625), (5,short,278.29449233400754), (4,long,480.86909615384786), (11,short,222.0055641344965), (9,medium,293.2234132305583), (6,long,598.8304861754714), (7,long,554.1280932802309), (10,medium,294.6734902128512), (9,long,405.4846256093821), (7,short,290.69249745466715), (7,medium,382.50144108559874), (5,medium,354.65170115173464))\r\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4eea600776b0d48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:46:16.918684Z",
     "start_time": "2025-01-23T10:46:16.100381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,69496)\r\n",
      "(1,53223)\r\n",
      "(2,49455)\r\n",
      "(3,87341)\r\n",
      "(4,78586)\r\n",
      "(5,76991)\r\n",
      "(6,49778)\r\n",
      "(7,58925)\r\n",
      "(8,64250)\r\n",
      "(9,72252)\r\n",
      "(10,71614)\r\n",
      "(11,110965)\r\n",
      "(12,44238)\r\n",
      "(13,52329)\r\n",
      "(14,50096)\r\n",
      "(15,73514)\r\n",
      "(16,58015)\r\n",
      "(17,62059)\r\n",
      "(18,77677)\r\n",
      "(19,60100)\r\n",
      "(20,79107)\r\n",
      "(21,27779)\r\n",
      "(22,59050)\r\n",
      "(23,33822)\r\n"
     ]
    }
   ],
   "source": [
    "rddFlightsO.mapPartitionsWithIndex((index, iter) => Iterator((index, iter.size))).collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6113768893852a26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:36:08.572480Z",
     "start_time": "2025-01-23T21:36:07.666787Z"
    }
   },
   "source": [
    "resultJobNotOptimized.sortBy(_._3, ascending = true).collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Array[(Int, String, Double)] = Array((11,short,222.00556413449337), (11,medium,254.4777731990232), (9,short,256.1263844227749), (10,short,259.3121553221906), (8,short,265.223595819795), (5,short,278.294492334017), (7,short,290.69249745467766), (9,medium,293.22341323056395), (10,medium,294.67349021286043), (6,short,296.05174334065117), (4,short,306.4335681610265), (8,medium,322.545062233574), (4,medium,331.0029844885145), (5,medium,354.65170115173936), (11,long,382.2554902106179), (7,medium,382.50144108560403), (6,medium,395.0468367755642), (9,long,405.4846256093826), (10,long,411.65239396939035), (8,long,462.04696232908344), (4,long,480.8690961538476), (5,long,533.1691284153799), (7,long,554.1280932802313), (6,long,598.8304861754746))\r\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "299c9bff9c1118d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:36:09.748722Z",
     "start_time": "2025-01-23T21:36:08.575490Z"
    }
   },
   "source": [
    "resultJobOptimized.sortBy(_._3, ascending = true).collect()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res7: Array[(Int, String, Double)] = Array((11,short,222.0055641344965), (11,medium,254.47777319902426), (9,short,256.12638442276415), (10,short,259.31215532217783), (8,short,265.2235958197836), (5,short,278.29449233400754), (7,short,290.69249745466715), (9,medium,293.2234132305583), (10,medium,294.6734902128512), (6,short,296.05174334064077), (4,short,306.43356816102596), (8,medium,322.5450622335694), (4,medium,331.0029844885144), (5,medium,354.65170115173464), (11,long,382.2554902106189), (7,medium,382.50144108559874), (6,medium,395.04683677555823), (9,long,405.4846256093821), (10,long,411.65239396938625), (8,long,462.04696232908634), (4,long,480.86909615384786), (5,long,533.1691284153735), (7,long,554.1280932802309), (6,long,598.8304861754714))\r\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "2d05f2fa-3fd0-4c2c-ad56-272db2ca66cc",
   "metadata": {},
   "source": [
    "Questa cella, serve a liberare la memoria ed è stata eseguita solo quando necessario per motivi di *debugging*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc301cd1-e16f-4cdf-a813-87158ace9b42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:50:07.862915Z",
     "start_time": "2025-01-23T12:50:07.639452Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.getPersistentRDDs.foreach(_._2.unpersist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e471e23c-b19c-4903-ad3f-89fc32ec610a",
   "metadata": {},
   "source": [
    "## Salvataggio dei risultati su file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a687d9ab92eb8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:40:15.060137Z",
     "start_time": "2025-01-23T12:40:14.193201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SaveMode\r\n",
       "jobNotOptimized: String = ../../../../output/jobNotOptimized\r\n",
       "jobOptimized: String = ../../../../output/jobOptimized\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SaveMode\n",
    "\n",
    "val jobNotOptimized = \"../../../../output/jobNotOptimized\"\n",
    "val jobOptimized = \"../../../../output/jobOptimized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94d29b-8e5f-46dc-8a01-efdf9125139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultJobNotOptimized\n",
    "  .coalesce(1)\n",
    "  .toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(jobNotOptimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804c524-7d52-485c-a902-6505892fe7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultJobOptimized\n",
    "  .coalesce(1)\n",
    "  .toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(jobOptimized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
