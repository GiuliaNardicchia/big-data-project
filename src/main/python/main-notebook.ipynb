{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45909d062047387d",
   "metadata": {},
   "source": [
    "# Obiettivo del progetto\n",
    "Dopo aver analizzato e compreso i dati, si vuole studiare meglio la correlazione riscontrata tra distanza e prezzo e si è individuato l'obiettivo del progetto. L'obiettivo è quello di verificare se c’è una stagionalità, nella quale i prezzi per alcuni mesi sono molto più elevati rispetto ad altri o se ci sono grandi variazioni di prezzo tra i diversi mesi rispetto alle diverse distanze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff5699d07ef8e27",
   "metadata": {},
   "source": [
    "## Descrizione del job proposto\n",
    "Avendo a disposizione un solo file *.csv* si è pensato si usare un pattern di tipo *self-join*:\n",
    "\n",
    "-\t**Prima aggregazione**: aggregare per ogni combinazione di aeroporto di partenza e destinazione (*startingAeroport* e *destinationAeroport*) per ottenere la distanza media di viaggio (*totalTravelDistance*). A partire dalla distanza media generare una nuova colonna che indichi la fascia di distanza del volo (breve distanza, media distanza, lunga distanza);\n",
    "\n",
    "-\t**Join**: unire il dataset originale con il risultato ottenuto;\n",
    "\n",
    "-\t**Seconda aggregazione**: aggregare per fascia di distanza e mese (*flightDate*, da cui si ricava il mese) per ottenere per ciascuna combinazione il prezzo medio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae506c8e35674206",
   "metadata": {},
   "source": [
    "### Caricamento libreria Spark\n",
    "\n",
    "Per prima cosa, si deve importare la libreria spark per avviare una `spark-shell`; in seguito verrà mostrato il link tramite il quale è possibile accedere all'interfaccia utente di Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb23d8dd5e72ce9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:54:23.042344Z",
     "start_time": "2025-01-23T12:54:09.887241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.9:4040\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1737636855478)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f69bc549d0a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "// DO NOT EXECUTE - this is needed just to avoid showing errors in the following cells\n",
    "val sc = spark.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c45630c708235f",
   "metadata": {},
   "source": [
    "### Parser del file .csv\n",
    "\n",
    "Nella cella sottostante è implementata una `case class Flight` con come parametri tutte le colonne(*) presenti nel file .csv descritto nel notebook [data-exploration.ipynb](./data-exploration.ipynb) e un `FlightParser` che consentente l'estrazione delle informazioni necessarie per popolare l'oggetto RDD di Spark.\n",
    "\n",
    "(*) per risolvere il `job` proposto verranno utilizzate solo alcune delle colonne."
   ]
  },
  {
   "cell_type": "code",
   "id": "51c8479048aa4b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T14:52:00.905713Z",
     "start_time": "2025-01-23T14:52:00.890713Z"
    }
   },
   "source": [
    "import java.text.SimpleDateFormat\n",
    "import java.util.Calendar\n",
    "\n",
    "/**\n",
    " * Flight case class.\n",
    " */\n",
    "case class Flight(\n",
    "    legId: String,\n",
    "    searchMonth: Int,\n",
    "    flightMonth: Int,\n",
    "    startingAirport: String,\n",
    "    destinationAirport: String,\n",
    "    fareBasisCode: String,\n",
    "    travelDuration: String,\n",
    "    elapsedDays: Int,\n",
    "    isBasicEconomy: Boolean,\n",
    "    isRefundable: Boolean,\n",
    "    isNonStop: Boolean,\n",
    "    baseFare: Double,\n",
    "    totalFare: Double,\n",
    "    seatsRemaining: Int,\n",
    "    totalTravelDistance: Double,\n",
    "    segmentsDepartureTimeEpochSeconds: String,\n",
    "    segmentsDepartureTimeRaw: String,\n",
    "    segmentsArrivalTimeEpochSeconds: String,\n",
    "    segmentsArrivalTimeRaw: String,\n",
    "    segmentsArrivalAirportCode: String,\n",
    "    segmentsDepartureAirportCode: String,\n",
    "    segmentsAirlineName: String,\n",
    "    segmentsAirlineCode: String,\n",
    "    segmentsEquipmentDescription: String,\n",
    "    segmentsDurationInSeconds: String,\n",
    "    segmentsDistance: String,\n",
    "    segmentsCabinCode: String\n",
    ") extends Serializable\n",
    "\n",
    "/**\n",
    " * Flight parser.\n",
    " */\n",
    "object FlightParser extends Serializable {\n",
    "\n",
    "  val comma = \",\"\n",
    "\n",
    "  /**\n",
    "   * Convert from date (String) to month (Int).\n",
    "   * @param dateString the date\n",
    "   * @return the month\n",
    "   */\n",
    "  def monthFromDate(dateString: String): Int = {\n",
    "    val sdf = new SimpleDateFormat(\"yyyy-MM-dd\")\n",
    "    val date = sdf.parse(dateString.trim)\n",
    "    val cal = Calendar.getInstance()\n",
    "    cal.setTime(date)\n",
    "    cal.get(Calendar.MONTH) + 1\n",
    "  }\n",
    "\n",
    "  /**\n",
    "   * Function to parse flights records.\n",
    "   * @param line that has to be parsed\n",
    "   * @return Flight object, None in case of input errors\n",
    "   */\n",
    "  def parseFlightLine(line: String): Option[Flight] = {\n",
    "    try {\n",
    "      val columns = line.split(comma)\n",
    "      Some(\n",
    "        Flight(\n",
    "          legId = columns(0).trim,\n",
    "          searchMonth = monthFromDate(columns(1)),\n",
    "          flightMonth = monthFromDate(columns(2)),\n",
    "          startingAirport = columns(3).trim,\n",
    "          destinationAirport = columns(4).trim,\n",
    "          fareBasisCode = columns(5).trim,\n",
    "          travelDuration = columns(6).trim,\n",
    "          elapsedDays = columns(7).trim.toInt,\n",
    "          isBasicEconomy = columns(8).trim.toBoolean,\n",
    "          isRefundable = columns(9).trim.toBoolean,\n",
    "          isNonStop = columns(10).trim.toBoolean,\n",
    "          baseFare = columns(11).trim.toDouble,\n",
    "          totalFare = columns(12).trim.toDouble,\n",
    "          seatsRemaining = columns(13).trim.toInt,\n",
    "          totalTravelDistance = columns(14).trim.toDouble,\n",
    "          segmentsDepartureTimeEpochSeconds = columns(15).trim,\n",
    "          segmentsDepartureTimeRaw = columns(16).trim,\n",
    "          segmentsArrivalTimeEpochSeconds = columns(17).trim,\n",
    "          segmentsArrivalTimeRaw = columns(18).trim,\n",
    "          segmentsArrivalAirportCode = columns(19).trim,\n",
    "          segmentsDepartureAirportCode = columns(20).trim,\n",
    "          segmentsAirlineName = columns(21).trim,\n",
    "          segmentsAirlineCode = columns(22).trim,\n",
    "          segmentsEquipmentDescription = columns(23).trim,\n",
    "          segmentsDurationInSeconds = columns(24).trim,\n",
    "          segmentsDistance = columns(25).trim,\n",
    "          segmentsCabinCode = columns(26).trim\n",
    "        )\n",
    "      )\n",
    "    } catch {\n",
    "      case e: Exception =>\n",
    "        // println(s\"Errore durante il parsing della riga '$line': ${e.getMessage}\")\n",
    "        None\n",
    "    }\n",
    "  }\n",
    "}"
   ],
   "outputs": [
    {
     "ename": "<console>",
     "evalue": " error: incomplete input",
     "output_type": "error",
     "traceback": [
      "<console>: error: incomplete input"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "d195400e1cea1b18",
   "metadata": {},
   "source": [
    "### Caricamento dei dati\n",
    "\n",
    "Con la seguente cella si effettua il caricamento del file *itineraries-sample\\<N\\>.csv*, dove con N si intende la percentuale di dati campionati dal file originale di 31,09 GB.\n",
    "\n",
    "I file disponibili sono scaricabili dalla cartella su [OneDrive](https://liveunibo-my.sharepoint.com/:f:/g/personal/giulia_nardicchia_studio_unibo_it/Ei2686kRO3JFrY-4LnImGpwBtge9FRErDnIgvT2h2QB-Pg?e=VrufWl) e hanno percentuale: `02`, `16` e `33`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8681b935c9353693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:54:29.537804Z",
     "start_time": "2025-01-23T12:54:28.077672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasetsPath: String = ../../../../datasets/big/\r\n",
       "fileName: String = itineraries-sample33.csv\r\n",
       "rawData: org.apache.spark.rdd.RDD[String] = ../../../../datasets/big/itineraries-sample33.csv MapPartitionsRDD[1] at textFile at <console>:30\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val datasetsPath = \"../../../../datasets/big/\"\n",
    "val fileName = \"itineraries-sample16.csv\"\n",
    "\n",
    "val rawData = sc.textFile(datasetsPath + fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad3c19d0de51fa",
   "metadata": {},
   "source": [
    "Trasformazione di un RDD composto da dati grezzi (*rawData*) in un RDD di oggetti `Flight`. La funzione `FlightParser.parseFlightLine` analizza ogni riga. `flatMap` appiattisce i risultati, scartando automaticamente le righe non valide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8c35cd3020a7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T17:45:26.211464Z",
     "start_time": "2025-01-22T17:45:24.846304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rddFlights: org.apache.spark.rdd.RDD[Flight] = MapPartitionsRDD[2] at flatMap at <console>:28\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rddFlights = rawData.flatMap(FlightParser.parseFlightLine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd44f9230e1434",
   "metadata": {},
   "source": [
    "Per verificare che non ci siano stati problemi di *parsing*, con la cella seguente si vuole eseguire un'azione. La funzione `count()` calcola il numero di righe valide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411a20cf90856722",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-22T17:45:31.790120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Long = 1520662\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddFlights.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500dc766c51eab",
   "metadata": {},
   "source": [
    "### Prima aggregazione\n",
    "\n",
    "Innanzitutto si utilizza `map` per eliminare tutte le colonne che non servono a svolgere il job proposto e per trasformare i dati di tipo (chiave, valore). Si vuole aggregare per ogni combinazione di aeroporto di partenza e destinazione (*startingAeroport* e *destinationAeroport*) per ottenere la distanza media di viaggio (*totalTravelDistance*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3928b8618a571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avgDistances: org.apache.spark.rdd.RDD[((String, String), Double)] = MapPartitionsRDD[5] at mapValues at <console>:33\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val avgDistances = rddFlights\n",
    "  .map(flight => ((flight.startingAirport, flight.destinationAirport), flight.totalTravelDistance))\n",
    "  .aggregateByKey((0.0, 0))(\n",
    "    (acc, travelDistance) => (acc._1 + travelDistance, acc._2 + 1),\n",
    "    (acc1, acc2) => (acc1._1 + acc2._1, acc1._2 + acc2._2)\n",
    "  )\n",
    "  .mapValues { case (sumDistance, count) => sumDistance / count }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f52f39-34a4-4c7c-832f-f40b96ce0570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[((String, String), Double)] = Array(((BOS,LGA),406.6977958842578), ((IAD,ORD),841.525204359673), ((EWR,PHL),1039.5994575045208), ((DTW,LGA),694.1526669795088), ((OAK,DFW),2123.889001864091), ((ATL,DEN),1513.575124745888), ((IAD,CLT),587.9657102869139), ((DEN,LGA),1804.57909562639), ((DTW,EWR),736.2682451253482), ((LGA,DFW),1455.155069582505), ((OAK,JFK),3126.575707702436), ((DEN,DTW),1578.6580700623254), ((JFK,IAD),703.4175354183374), ((ORD,MIA),1521.1334047682828), ((IAD,DFW),1363.3681891954557), ((DEN,PHL),1852.40172900494), ((OAK,DEN),1419.471807628524), ((BOS,JFK),261.94046744083494), ((SFO,JFK),2652.746982695943), ((DTW,MIA),1462.8436163714111), ((PHL,OAK),2949.3589503280223), ((CLT,LGA),665.3443708609271), ((DTW,JFK),842.9147381242387), ((ATL,IAD),647.0074156470153), (...\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgDistances.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f64718cfaaeafc",
   "metadata": {},
   "source": [
    "A partire dalla distanza media generare una nuova colonna che indichi la fascia di distanza del volo (breve distanza, media distanza, lunga distanza).\n",
    "\n",
    "Poiché usare valori numerici *hard coded* è una *bad practice*, si è deciso di utilizzare il minimo, il massimo e il numero di classi per calcolare dinamicamente l'intervallo delle fasce di distanza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b489572-22b4-4038-a7fa-0081398ed80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "globals: (Double, Double) = (185.0,3366.947416137806)\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val globals = avgDistances\n",
    "    .aggregate((Double.MaxValue, Double.MinValue))(\n",
    "        (acc, value) => (math.min(acc._1, value._2), math.max(acc._2, value._2)),\n",
    "        (acc1, acc2) => (math.min(acc1._1, acc2._1), math.max(acc1._2, acc2._2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51ab6cf21a842b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minDistance: Double = 185.0\r\n",
       "maxDistance: Double = 3366.947416137806\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (minDistance, maxDistance) = globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d113be73d8f55809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numClasses: Int = 3\r\n",
       "range: Double = 1060.649138712602\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numClasses = 3\n",
    "\n",
    "val range = (maxDistance - minDistance) / numClasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c5f70d0a66232",
   "metadata": {},
   "source": [
    "Per calcolare l'intervallo in maniera equidistante sono stati adottati i seguenti limiti:\n",
    "- **Breve**: se la distanza media è inferiore a *minimo + intervallo*;\n",
    "\n",
    "- **Media**: se la distanza media è compresa tra *[minimo + intervallo; minimo + 2 * intervallo)*;\n",
    "\n",
    "- **Lunga**: se la distanza media è superiore a *minimo + (numero classi - 1) * intervallo*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18d2cf93-74f7-4176-88c4-ce4303f1ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifiedDistances: org.apache.spark.rdd.RDD[((String, String), String)] = MapPartitionsRDD[6] at mapValues at <console>:30\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val classifiedDistances = avgDistances.mapValues {\n",
    "    case d if d < minDistance + range => \"Breve\"\n",
    "    case d if d < minDistance + (numClasses - 1) * range => \"Media\"\n",
    "    case _ => \"Lunga\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f60e39b-ecff-4bcf-ab28-074ba9e0d677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Array[((String, String), String)] = Array(((BOS,LGA),Breve), ((IAD,ORD),Breve), ((EWR,PHL),Breve), ((DTW,LGA),Breve), ((OAK,DFW),Media), ((ATL,DEN),Media), ((IAD,CLT),Breve), ((DEN,LGA),Media), ((DTW,EWR),Breve), ((LGA,DFW),Media), ((OAK,JFK),Lunga), ((DEN,DTW),Media), ((JFK,IAD),Breve), ((ORD,MIA),Media), ((IAD,DFW),Media), ((DEN,PHL),Media), ((OAK,DEN),Media), ((BOS,JFK),Breve), ((SFO,JFK),Lunga), ((DTW,MIA),Media), ((PHL,OAK),Lunga), ((CLT,LGA),Breve), ((DTW,JFK),Breve), ((ATL,IAD),Breve), ((ATL,MIA),Breve), ((DTW,IAD),Breve), ((OAK,LGA),Lunga), ((SFO,EWR),Lunga), ((IAD,SFO),Lunga), ((CLT,SFO),Lunga), ((BOS,ATL),Breve), ((LAX,DEN),Breve), ((DEN,JFK),Media), ((BOS,LAX),Lunga), ((SFO,IAD),Lunga), ((DTW,DEN),Media), ((ORD,LGA),Breve), ((ATL,OAK),Lunga), ((MIA,CLT),Breve), ((EWR,LG...\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiedDistances.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24023d49bd4355e",
   "metadata": {},
   "source": [
    "### Join + Seconda aggregazione\n",
    "\n",
    "Unire il dataset originale con il risultato ottenuto e aggregare per fascia di distanza e mese (*flightDate*, da cui si ricava il mese) per ottenere per ciascuna combinazione il prezzo medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc88d7785805c488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resultJob: org.apache.spark.rdd.RDD[(Int, String, Double)] = MapPartitionsRDD[13] at map at <console>:35\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val resultJob = rddFlights\n",
    "  .map(flight => ((flight.startingAirport, flight.destinationAirport), (flight.flightMonth, flight.totalFare)))\n",
    "  .join(classifiedDistances)\n",
    "  .map {\n",
    "    case (_, ((flightMonth, totalFare), classification)) => ((flightMonth, classification), (totalFare, 1))\n",
    "  }\n",
    "  .reduceByKey((acc, totalFare) => (acc._1 + totalFare._1, acc._2 + totalFare._2))\n",
    "  .map {\n",
    "    case ((flightMonth, classification), (sumTotalFare, count)) => (flightMonth, classification, sumTotalFare / count)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cfcbba0-59f0-42fa-a35f-93b1b178ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Array[(Int, String, Double)] = Array((5,Breve,278.2944923340169), (10,Media,294.67349021285935), (5,Media,354.6517011517386), (8,Lunga,462.04696232908327), (6,Breve,296.05174334065094), (11,Media,254.47777319902355), (11,Breve,222.00556413449337), (7,Lunga,554.1280932802313), (5,Lunga,533.1691284153799), (9,Media,293.22341323056406), (9,Breve,256.1263844227748), (6,Media,395.04683677556426), (11,Lunga,382.2554902106178), (7,Breve,290.6924974546775), (10,Lunga,411.65239396939035), (7,Media,382.5014410856043), (8,Media,322.54506223357464), (4,Breve,306.4335681610265), (6,Lunga,598.8304861754743), (8,Breve,265.2235958197947), (10,Breve,259.31215532219113), (4,Media,331.0029844885145), (4,Lunga,480.8690961538476), (9,Lunga,405.4846256093827))\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultJob.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bfd7ca0e66fbb2",
   "metadata": {},
   "source": [
    "## Job Not Optimized\n",
    "\n",
    "A partire dal codice scritto nelle precedenti celle, si è proceduto a *\"rifattorizzare\"* l'implementazione, di seguito il *job* non ottimizzato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a6651-59d3-4191-8d5b-a9e60c15ed6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-23T13:41:28.590484Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val rddFlightsNO = rawData.flatMap(FlightParser.parseFlightLine)\n",
    "    // (k,v) => (startingAirport, destinationAirport), (totalTravelDistance, flightDate, totalFare))\n",
    "    .map(flight => ((flight.startingAirport, flight.destinationAirport),\n",
    "                    (flight.totalTravelDistance, flight.flightMonth, flight.totalFare)))\n",
    "\n",
    "val avgDistancesNO = rddFlightsNO\n",
    "    .aggregateByKey((0.0, 0))(\n",
    "        (acc, travelDistance) => (acc._1 + travelDistance._1, acc._2 + 1),\n",
    "        (acc1, acc2) => (acc1._1 + acc2._1, acc1._2 + acc2._2)\n",
    "    )\n",
    "    // (k,v) => ((startingAirport, destinationAirport), avgDistance)\n",
    "    .mapValues { case (sumDistance, count) => sumDistance / count }\n",
    "\n",
    "val (minDistanceNO, maxDistanceNO) = avgDistancesNO\n",
    "    .aggregate((Double.MaxValue, Double.MinValue))(\n",
    "        (acc, avgDistance) => (math.min(acc._1, avgDistance._2), math.max(acc._2, avgDistance._2)),\n",
    "        (acc1, acc2) => (math.min(acc1._1, acc2._1), math.max(acc1._2, acc2._2))\n",
    "    )\n",
    "\n",
    "val numClassesNO = 3\n",
    "val rangeNO = (maxDistanceNO - minDistanceNO) / numClassesNO\n",
    "\n",
    "val resultJobNotOptimized = avgDistancesNO\n",
    "    .mapValues {\n",
    "      case d if d < minDistanceNO + rangeNO => \"Breve\"\n",
    "      case d if d < minDistanceNO + (numClassesNO - 1) * rangeNO => \"Media\"\n",
    "      case _ => \"Lunga\"\n",
    "    } // (k,v) => ((startingAirport, destinationAirport), classification)\n",
    "    .join(rddFlightsNO)\n",
    "    .map { case (_, (classification, (_, month, totalFare))) => ((month, classification), (totalFare, 1)) }\n",
    "    .reduceByKey((acc, totalFare) => (acc._1 + totalFare._1, acc._2 + totalFare._2))\n",
    "    .map { case ((month, classification), (sumTotalFare : Double, count: Int)) => (month, classification, sumTotalFare / count) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efbfcf7-5bb8-48f6-9a99-573b9edbb153",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultJobNotOptimized.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f46674-634a-458a-ab23-e48cdda23546",
   "metadata": {},
   "source": [
    "### Considerazioni sulle ottimizzazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bcf39a-68ec-42e2-a12c-798c49de3829",
   "metadata": {},
   "source": [
    "- Cache/Persist\n",
    "- Repartition/PartitionBy\n",
    "- Broadcast variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3bc2fbd8d752bfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:44:54.591520Z",
     "start_time": "2025-01-23T10:44:53.824429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Option[org.apache.spark.Partitioner] = None\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddFlightsNO.partitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bd9a2e0726109e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:44:54.976896Z",
     "start_time": "2025-01-23T10:44:54.594363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Int = 19\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddFlightsNO.partitions.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bebe4e41d4c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rddFlightsNO.mapPartitionsWithIndex((index, iter) => Iterator((index, iter.size))).collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc37760176ffe090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:56:29.369262Z",
     "start_time": "2025-01-23T10:56:28.437017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res13: Int = 8\r\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java.lang.Runtime.getRuntime.availableProcessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b99a90a1972245d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:03:18.876072Z",
     "start_time": "2025-01-23T11:03:18.565568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res22: Int = 8\r\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b5fde3d3054573f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:15:34.081673Z",
     "start_time": "2025-01-23T11:15:33.924557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.eventLog.enabled: true\r\n",
      "spark.driver.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\r\n",
      "spark.driver.cores: 4\r\n",
      "spark.app.submitTime: 1737629015318\r\n",
      "spark.eventLog.dir: file:///c:/spark-3.5.1-bin-hadoop3/history/\r\n",
      "spark.driver.memory: 4g\r\n",
      "spark.app.startTime: 1737629015468\r\n",
      "spark.executor.id: driver\r\n",
      "spark.app.name: spylon-kernel\r\n",
      "spark.repl.class.uri: spark://192.168.1.9:57307/classes\r\n",
      "spark.history.fs.logDirectory: file:///c:/spark-3.5.1-bin-hadoop3/history/\r\n",
      "spark.repl.class.outputDir: C:\\Users\\HP\\AppData\\Local\\Temp\\tmpx15xnw93\r\n",
      "spark.driver.port: 57307\r\n",
      "spark.rdd.compress: True\r\n",
      "spark.executor.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\r\n",
      "spark.serializer.objectStreamReset: 100\r\n",
      "spark.master: local[*]\r\n",
      "spark.submit.pyFiles: \r\n",
      "spark.submit.deployMode: client\r\n",
      "spark.app.id: local-1737629016653\r\n",
      "spark.driver.host: 192.168.1.9\r\n",
      "spark.ui.showConsoleProgress: true\r\n"
     ]
    }
   ],
   "source": [
    "sc.getConf.getAll.foreach { case (key, value) =>\n",
    "  println(s\"$key: $value\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64baa8da4978b354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T11:15:19.638414Z",
     "start_time": "2025-01-23T11:15:19.535545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: String = 4\r\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf.get(\"spark.driver.cores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fb60a-caca-4e64-b447-6c0f1a49cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.getConf.get(\"spark.driver.memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2914a2-411f-459c-b825-513953211cb3",
   "metadata": {},
   "source": [
    "## Job Optimized\n",
    "\n",
    "Una volta capite quali tecniche di ottimizzazione sono da adottare per migliorare le performance, sia in termini di tempo sia in termini di computazione, è stato riscritto il *main job* e si è ottenuto il seguente codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9213ee75-718d-49ef-99d8-e84dc43cbd67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:57:41.928802Z",
     "start_time": "2025-01-23T12:54:38.318925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.storage.StorageLevel._\r\n",
       "import org.apache.spark.HashPartitioner\r\n",
       "numPartitions: Int = 24\r\n",
       "p: org.apache.spark.HashPartitioner = org.apache.spark.HashPartitioner@18\r\n",
       "rddFlightsO: org.apache.spark.rdd.RDD[((String, String), (Double, Int, Double))] = ShuffledRDD[4] at partitionBy at <console>:39\r\n",
       "avgDistancesO: org.apache.spark.rdd.RDD[((String, String), Double)] = MapPartitionsRDD[6] at mapValues at <console>:48\r\n",
       "minDistanceO: Double = 185.0\r\n",
       "maxDistanceO: Double = 3364.8721770632446\r\n",
       "numClassesO: Int = 3\r\n",
       "rangeO: Double = 1059.9573923544149\r\n",
       "resultJobOptimized: org.apache.spark.rdd.RDD[(Int, String, Double)] = MapPartitionsRDD[13] at map at <console>:72\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.storage.StorageLevel._\n",
    "import org.apache.spark.HashPartitioner\n",
    "\n",
    "val numPartitions = 24\n",
    "val p = new HashPartitioner(numPartitions)\n",
    "\n",
    "val rddFlightsO = rawData.flatMap(FlightParser.parseFlightLine)\n",
    "    // (k,v) => (startingAirport, destinationAirport), (totalTravelDistance, flightDate, totalFare))\n",
    "    .map(flight => ((flight.startingAirport, flight.destinationAirport), \n",
    "                    (flight.totalTravelDistance, flight.flightMonth, flight.totalFare)))\n",
    "    .partitionBy(p)\n",
    "    //.persist(MEMORY_AND_DISK_SER)\n",
    "    .cache()\n",
    "\n",
    "val avgDistancesO = rddFlightsO\n",
    "    .aggregateByKey((0.0, 0))(\n",
    "    (acc, travelDistance) => (acc._1 + travelDistance._1, acc._2 + 1),\n",
    "    (acc1, acc2) => (acc1._1 + acc2._1, acc1._2 + acc2._2)\n",
    "    )\n",
    "    // (k,v) => ((startingAirport, destinationAirport), avgDistance)\n",
    "    .mapValues { case (sumDistance, count) => sumDistance / count }\n",
    "    //.persist(MEMORY_AND_DISK_SER)\n",
    "    .cache()\n",
    "\n",
    "val (minDistanceO, maxDistanceO) = sc.broadcast(avgDistancesO\n",
    "    .aggregate((Double.MaxValue, Double.MinValue))(\n",
    "        (acc, avgDistance) => (Math.min(acc._1, avgDistance._2), Math.max(acc._2, avgDistance._2)),\n",
    "        (acc1, acc2) => (Math.min(acc1._1, acc2._1), Math.max(acc1._2, acc2._2))\n",
    "    )\n",
    ").value\n",
    "\n",
    "val numClassesO = 3\n",
    "val rangeO = (maxDistanceO - minDistanceO) / numClassesO\n",
    "\n",
    "val resultJobOptimized = avgDistancesO\n",
    "    .mapValues {\n",
    "      case d if d < minDistanceO + rangeO => \"Breve\"\n",
    "      case d if d < minDistanceO + (numClassesO - 1) * rangeO => \"Media\"\n",
    "      case _ => \"Lunga\"\n",
    "    } // (k,v) => ((startingAirport, destinationAirport), classification)\n",
    "    .join(rddFlightsO)\n",
    "    .map { case (_, (classification, (_, month, totalFare))) => ((month, classification), (totalFare, 1)) }\n",
    "    .reduceByKey((acc, totalFare) => (acc._1 + totalFare._1, acc._2 + totalFare._2))\n",
    "    .map { case ((month, classification), (sumTotalFare, count)) => (month, classification, sumTotalFare / count) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e60328d17e7ae1e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:46:13.819719Z",
     "start_time": "2025-01-23T10:46:13.264071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Int = 24\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddFlightsO.partitions.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50cb4e7-dabe-4415-a9b8-77f778977fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T13:05:26.040784Z",
     "start_time": "2025-01-23T13:03:59.522627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Array[(Int, String, Double)] = Array((8,Lunga,462.1341161278131), (5,Breve,279.1820068768932), (4,Lunga,478.8757304680619), (10,Breve,259.4922130163935), (4,Media,330.82723213972565), (7,Media,381.9976774607331), (8,Media,323.0179563552248), (11,Lunga,379.7274380195217), (5,Media,355.50055378636335), (7,Lunga,553.9241742944876), (6,Breve,295.78015634556124), (9,Breve,256.14031435189816), (10,Media,295.33420848194424), (7,Breve,290.50101731575063), (11,Media,252.53460665408082), (10,Lunga,412.06327417998796), (6,Media,394.8708908988052), (4,Breve,303.8563464103333), (6,Lunga,598.172967357456), (5,Lunga,534.0579715305116), (11,Breve,221.51950154015825), (9,Lunga,404.66355996909977), (8,Breve,265.16307517222884), (9,Media,293.27557365590724))\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultJobOptimized.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4eea600776b0d48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:46:16.918684Z",
     "start_time": "2025-01-23T10:46:16.100381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,69496)\r\n",
      "(1,53223)\r\n",
      "(2,49455)\r\n",
      "(3,87341)\r\n",
      "(4,78586)\r\n",
      "(5,76991)\r\n",
      "(6,49778)\r\n",
      "(7,58925)\r\n",
      "(8,64250)\r\n",
      "(9,72252)\r\n",
      "(10,71614)\r\n",
      "(11,110965)\r\n",
      "(12,44238)\r\n",
      "(13,52329)\r\n",
      "(14,50096)\r\n",
      "(15,73514)\r\n",
      "(16,58015)\r\n",
      "(17,62059)\r\n",
      "(18,77677)\r\n",
      "(19,60100)\r\n",
      "(20,79107)\r\n",
      "(21,27779)\r\n",
      "(22,59050)\r\n",
      "(23,33822)\r\n"
     ]
    }
   ],
   "source": [
    "rddFlightsO.mapPartitionsWithIndex((index, iter) => Iterator((index, iter.size))).collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6113768893852a26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:39:05.026449Z",
     "start_time": "2025-01-23T12:39:04.116944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Array[(Int, String, Double)] = Array((11,Breve,222.00556413449337), (11,Media,254.4777731990232), (9,Breve,256.1263844227749), (10,Breve,259.3121553221906), (8,Breve,265.223595819795), (5,Breve,278.294492334017), (7,Breve,290.69249745467766), (9,Media,293.22341323056395), (10,Media,294.67349021286043), (6,Breve,296.05174334065117), (4,Breve,306.4335681610265), (8,Media,322.545062233574), (4,Media,331.0029844885145), (5,Media,354.65170115173936), (11,Lunga,382.2554902106179), (7,Media,382.50144108560403), (6,Media,395.0468367755642), (9,Lunga,405.4846256093826), (10,Lunga,411.65239396939035), (8,Lunga,462.04696232908344), (4,Lunga,480.8690961538476), (5,Lunga,533.1691284153799), (7,Lunga,554.1280932802313), (6,Lunga,598.8304861754746))\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultJobNotOptimized.sortBy(_._3, ascending = true).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299c9bff9c1118d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:39:05.749063Z",
     "start_time": "2025-01-23T12:39:05.028458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Array[(Int, String, Double)] = Array((11,Breve,222.0055641344965), (11,Media,254.47777319902426), (9,Breve,256.12638442276415), (10,Breve,259.31215532217783), (8,Breve,265.2235958197836), (5,Breve,278.29449233400754), (7,Breve,290.69249745466715), (9,Media,293.2234132305583), (10,Media,294.6734902128512), (6,Breve,296.05174334064077), (4,Breve,306.43356816102596), (8,Media,322.5450622335694), (4,Media,331.0029844885144), (5,Media,354.65170115173464), (11,Lunga,382.2554902106189), (7,Media,382.50144108559874), (6,Media,395.04683677555823), (9,Lunga,405.4846256093821), (10,Lunga,411.65239396938625), (8,Lunga,462.04696232908634), (4,Lunga,480.86909615384786), (5,Lunga,533.1691284153735), (7,Lunga,554.1280932802309), (6,Lunga,598.8304861754714))\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultJobOptimized.sortBy(_._3, ascending = true).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d05f2fa-3fd0-4c2c-ad56-272db2ca66cc",
   "metadata": {},
   "source": [
    "Questa cella, serve a liberare la memoria ed è stata eseguita solo quando necessario per motivi di *debugging*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc301cd1-e16f-4cdf-a813-87158ace9b42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:50:07.862915Z",
     "start_time": "2025-01-23T12:50:07.639452Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.getPersistentRDDs.foreach(_._2.unpersist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e471e23c-b19c-4903-ad3f-89fc32ec610a",
   "metadata": {},
   "source": [
    "## Salvataggio dei risultati su file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a687d9ab92eb8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T12:40:15.060137Z",
     "start_time": "2025-01-23T12:40:14.193201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SaveMode\r\n",
       "jobNotOptimized: String = ../../../../output/jobNotOptimized\r\n",
       "jobOptimized: String = ../../../../output/jobOptimized\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SaveMode\n",
    "\n",
    "val jobNotOptimized = \"../../../../output/jobNotOptimized\"\n",
    "val jobOptimized = \"../../../../output/jobOptimized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94d29b-8e5f-46dc-8a01-efdf9125139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultJobNotOptimized\n",
    "  .coalesce(1)\n",
    "  .toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(jobNotOptimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804c524-7d52-485c-a902-6505892fe7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultJobOptimized\n",
    "  .coalesce(1)\n",
    "  .toDF().write.format(\"csv\").mode(SaveMode.Overwrite).save(jobOptimized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
